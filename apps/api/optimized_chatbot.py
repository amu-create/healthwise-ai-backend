import os
import logging
import re
import asyncio
import time
from typing import Dict, List, Optional, Tuple
from django.conf import settings
from django.utils import timezone
from django.db.models import Q
from django.core.cache import cache
from apps.core.models import (
    ChatMessage, ChatSession, UserProfile, VectorizedChatHistory,
    DailyRecommendation, EXERCISE_CHOICES, FOOD_CATEGORIES
)
from openai import OpenAI
import traceback
import json
import numpy as np
from datetime import datetime, timedelta
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import torch
from concurrent.futures import ThreadPoolExecutor
import hashlib

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.DEBUG)
formatter = logging.Formatter('[%(asctime)s] %(levelname)s [%(name)s:%(lineno)d] %(message)s')
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)


class OptimizedHealthChatbot:
    """ìµœì í™”ëœ í—¬ìŠ¤ì¼€ì–´ AI ì±—ë´‡ - ìºì‹±ê³¼ ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ê°œì„ """
    
    # í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ê³µìœ  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
    _embeddings = None
    _vectorstore = None
    _executor = ThreadPoolExecutor(max_workers=4)
    
    def __init__(self):
        logger.debug("ğŸš€ OptimizedHealthChatbot ì´ˆê¸°í™” ì‹œì‘")
        try:
            api_key = settings.OPENAI_API_KEY
            self.client = OpenAI(api_key=api_key)
            self.max_recent_sessions = 7
            
            # Vectorstore ê´€ë ¨ ì„¤ì •
            self.vectorstore_path = os.path.join(settings.BASE_DIR, "api", "vectorstore")
            self.embedding_model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            
            # ìºì‹œ ì„¤ì •
            self.cache_timeout = 3600  # 1ì‹œê°„
            self.search_cache_timeout = 1800  # 30ë¶„
            
            # Vectorstore ì´ˆê¸°í™” (ì‹±ê¸€í†¤ íŒ¨í„´)
            if not OptimizedHealthChatbot._embeddings:
                self._initialize_shared_resources()
            
            logger.debug("âœ… OptimizedHealthChatbot ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ OptimizedHealthChatbot ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    
    @classmethod
    def _initialize_shared_resources(cls):
        """ê³µìœ  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)"""
        try:
            logger.info("ğŸ”§ ê³µìœ  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹œì‘")
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            cls._embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                model_kwargs={"device": "cuda" if torch.cuda.is_available() else "cpu"},
                encode_kwargs={'normalize_embeddings': True, 'batch_size': 32}
            )
            logger.info("âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # Vectorstore ë¡œë“œ
            vectorstore_path = os.path.join(settings.BASE_DIR, "api", "vectorstore")
            if os.path.exists(vectorstore_path):
                cls._vectorstore = FAISS.load_local(
                    vectorstore_path, 
                    cls._embeddings, 
                    allow_dangerous_deserialization=True
                )
                logger.info(f"âœ… Vectorstore ë¡œë“œ ì™„ë£Œ: {vectorstore_path}")
            else:
                logger.warning(f"âš ï¸ Vectorstore ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {vectorstore_path}")
                
        except Exception as e:
            logger.error(f"âŒ ê³µìœ  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def _get_cache_key(self, prefix: str, query: str, user_id: int = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        if user_id:
            key = f"{prefix}:{user_id}:{hashlib.md5(query.encode()).hexdigest()}"
        else:
            key = f"{prefix}:{hashlib.md5(query.encode()).hexdigest()}"
        return key
    
    def _search_pdf_knowledge_cached(self, query: str, k: int = 3) -> List[Dict]:
        """ìºì‹œëœ PDF vectorstore ê²€ìƒ‰"""
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._get_cache_key("pdf_search", query)
        
        # ìºì‹œ í™•ì¸
        cached_result = cache.get(cache_key)
        if cached_result is not None:
            logger.debug(f"âœ… PDF ê²€ìƒ‰ ìºì‹œ íˆíŠ¸: {cache_key}")
            return cached_result
        
        # ìºì‹œ ë¯¸ìŠ¤ - ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
        result = self._search_pdf_knowledge(query, k)
        
        # ê²°ê³¼ ìºì‹±
        cache.set(cache_key, result, self.search_cache_timeout)
        return result
    
    def _search_pdf_knowledge(self, query: str, k: int = 3) -> List[Dict]:
        """PDF vectorstoreì—ì„œ ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰"""
        if not OptimizedHealthChatbot._vectorstore:
            return []
            
        try:
            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            docs = OptimizedHealthChatbot._vectorstore.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, score in docs:
                # ì ìˆ˜ê°€ ë‚®ì€ ê²°ê³¼ëŠ” ì œì™¸ (ê´€ë ¨ì„±ì´ ë‚®ìŒ)
                if score > 0.8:  # ì„ê³„ê°’ ì¡°ì •
                    continue
                    
                results.append({
                    'content': doc.page_content,
                    'metadata': doc.metadata,
                    'source': doc.metadata.get('source', 'unknown'),
                    'score': score
                })
                
            logger.debug(f"âœ… PDF ì§€ì‹ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return results
            
        except Exception as e:
            logger.error(f"âŒ PDF ì§€ì‹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _search_pdf_knowledge_async(self, query: str, k: int = 3) -> List[Dict]:
        """ë¹„ë™ê¸° PDF ê²€ìƒ‰"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            OptimizedHealthChatbot._executor,
            self._search_pdf_knowledge_cached,
            query,
            k
        )
    
    def get_response(self, user, question: str) -> Dict:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„± (ìµœì í™”ëœ ë²„ì „)"""
        logger.debug("ğŸ¯ get_response í•¨ìˆ˜ ì‹œì‘")
        start_time = time.time()
        
        try:
            # 1. ê°„ë‹¨í•œ ì¸ì‚¬ë‚˜ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì€ ìºì‹œì—ì„œ í™•ì¸
            simple_response = self._check_simple_questions_cache(question)
            if simple_response:
                logger.debug(f"âœ… ê°„ë‹¨í•œ ì§ˆë¬¸ ìºì‹œ íˆíŠ¸: {time.time() - start_time:.2f}ì´ˆ")
                return simple_response
            
            # 2. ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            session = self.get_or_create_session(user)
            
            # 3. ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
            user_context = self._get_user_context_cached(user)
            
            # 4. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ (ë¹„ë™ê¸°)
            user_msg = ChatMessage.objects.create(
                user=user,
                session=session,
                sender='user',
                message=question,
                context={'action': 'question'}
            )
            
            # 5. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìºì‹œ ì‚¬ìš©)
            system_prompt = self._get_cached_system_prompt(user, user_context)
            
            # 6. í•„ìš”í•œ ê²½ìš°ì—ë§Œ PDF ê²€ìƒ‰ ìˆ˜í–‰
            pdf_knowledge = []
            if self._should_search_pdf(question):
                pdf_knowledge = self._search_pdf_knowledge_cached(question)
                logger.debug(f"ğŸ“š PDF ê²€ìƒ‰ ì™„ë£Œ: {len(pdf_knowledge)}ê°œ ë¬¸ì„œ")
            
            # 7. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ìµœì í™”)
            messages = self._build_optimized_conversation_context(
                user, session, system_prompt, question, pdf_knowledge
            )
            
            # 8. OpenAI API í˜¸ì¶œ
            logger.debug(f"ğŸ¤– OpenAI API í˜¸ì¶œ ì‹œì‘ (ê²½ê³¼: {time.time() - start_time:.2f}ì´ˆ)")
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                max_tokens=1000
            )
            
            answer = response.choices[0].message.content
            logger.debug(f"âœ… OpenAI ì‘ë‹µ ì™„ë£Œ (ê²½ê³¼: {time.time() - start_time:.2f}ì´ˆ)")
            
            # 9. ë´‡ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)
            ChatMessage.objects.create(
                user=user,
                session=session,
                sender='bot',
                message=answer,
                context={
                    'action': 'response',
                    'model': 'gpt-4o-mini',
                    'pdf_sources_used': len(pdf_knowledge),
                    'response_time': time.time() - start_time
                }
            )
            
            # 10. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (ì„ í˜¸ë„ ì¶”ì¶œ ë“±)
            self._schedule_background_tasks(user, question, answer)
            
            logger.info(f"ğŸ‰ ì „ì²´ ì‘ë‹µ ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
            
            return {
                'success': True,
                'response': answer,
                'raw_response': answer,
                'sources': len(pdf_knowledge),
                'user_context': user_context,
                'session_id': session.id,
                'response_time': time.time() - start_time
            }
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                'success': False,
                'response': "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'error': str(e),
                'response_time': time.time() - start_time
            }
    
    def _check_simple_questions_cache(self, question: str) -> Optional[Dict]:
        """ê°„ë‹¨í•œ ì§ˆë¬¸ì— ëŒ€í•œ ìºì‹œ í™•ì¸"""
        simple_patterns = [
            (r'ì•ˆë…•|í•˜ì´|hello|hi', "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"),
            (r'ê°ì‚¬|ê³ ë§ˆì›Œ|thanks?|thank you', "ì²œë§Œì—ìš”! ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”."),
            (r'ì˜ê°€|ë°”ì´|bye|goodbye', "ì•ˆë…•íˆ ê°€ì„¸ìš”! ê±´ê°•í•˜ì„¸ìš”!"),
        ]
        
        question_lower = question.lower()
        for pattern, response in simple_patterns:
            if re.search(pattern, question_lower):
                return {
                    'success': True,
                    'response': response,
                    'raw_response': response,
                    'sources': 0,
                    'user_context': None,
                    'cached': True
                }
        return None
    
    def _should_search_pdf(self, question: str) -> bool:
        """PDF ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        # íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°ì—ë§Œ ê²€ìƒ‰
        search_keywords = [
            'ìš´ë™', 'ì‹ë‹¨', 'ì˜ì–‘', 'ì¹¼ë¡œë¦¬', 'ë‹¨ë°±ì§ˆ', 'íƒ„ìˆ˜í™”ë¬¼',
            'ì§€ë°©', 'ë¹„íƒ€ë¯¼', 'ë¯¸ë„¤ë„', 'ë‹¤ì´ì–´íŠ¸', 'ë²Œí¬ì—…', 'ê·¼ìœ¡',
            'ìœ ì‚°ì†Œ', 'ë¬´ì‚°ì†Œ', 'ìŠ¤íŠ¸ë ˆì¹­', 'ìš”ê°€', 'í•„ë¼í…ŒìŠ¤'
        ]
        
        question_lower = question.lower()
        return any(keyword in question_lower for keyword in search_keywords)
    
    def _get_user_context_cached(self, user) -> Dict:
        """ìºì‹œëœ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        cache_key = f"user_context:{user.id}"
        cached_context = cache.get(cache_key)
        
        if cached_context:
            return cached_context
        
        context = self._get_user_context(user)
        cache.set(cache_key, context, 300)  # 5ë¶„ ìºì‹œ
        return context
    
    def _get_cached_system_prompt(self, user, user_context: Dict) -> str:
        """ìºì‹œëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        cache_key = f"system_prompt:{user.id}:{timezone.now().date()}"
        cached_prompt = cache.get(cache_key)
        
        if cached_prompt:
            return cached_prompt
        
        prompt = self._create_system_prompt(user, user_context)
        cache.set(cache_key, prompt, 3600)  # 1ì‹œê°„ ìºì‹œ
        return prompt
    
    def _build_optimized_conversation_context(self, user, session, system_prompt: str, 
                                            current_question: str, pdf_knowledge: List[Dict]) -> List[Dict]:
        """ìµœì í™”ëœ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        messages = [{"role": "system", "content": system_prompt}]
        
        # PDF ì§€ì‹ì´ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        if pdf_knowledge:
            knowledge_context = "\n\nì°¸ê³  ìë£Œ:\n"
            for idx, doc in enumerate(pdf_knowledge[:2]):  # ìƒìœ„ 2ê°œë§Œ ì‚¬ìš©
                knowledge_context += f"{idx+1}. {doc['content'][:300]}...\n"
            messages[0]["content"] += knowledge_context
        
        # í˜„ì¬ ì„¸ì…˜ì˜ ìµœê·¼ ëŒ€í™”ë§Œ í¬í•¨ (10ê°œë¡œ ì œí•œ)
        recent_messages = session.messages.order_by('-created_at')[:10]
        for msg in reversed(list(recent_messages)[1:]):  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
            if msg.sender == 'user':
                messages.append({"role": "user", "content": msg.message})
            else:
                messages.append({"role": "assistant", "content": msg.message})
        
        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        messages.append({"role": "user", "content": current_question})
        
        return messages
    
    def _schedule_background_tasks(self, user, question: str, answer: str):
        """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìŠ¤ì¼€ì¤„ë§"""
        # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸° ì‹¤í–‰
        OptimizedHealthChatbot._executor.submit(
            self._background_tasks, user, question, answer
        )
    
    def _background_tasks(self, user, question: str, answer: str):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë  ì‘ì—…ë“¤"""
        try:
            # ì„ í˜¸ë„ ì¶”ì¶œ
            combined_text = f"ì‚¬ìš©ì: {question}\nì±—ë´‡: {answer}"
            preferences = self._extract_preferences_from_text(combined_text)
            
            if any(preferences.values()):
                self._update_user_preferences(user, preferences)
            
            # ì¼ì¼ ì¶”ì²œ ìƒì„± (í•„ìš”í•œ ê²½ìš°)
            self._generate_daily_recommendations(user)
            
        except Exception as e:
            logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤íŒ¨: {str(e)}")
    
    # ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (get_or_create_session, _get_user_context ë“±)
    def get_or_create_session(self, user) -> ChatSession:
        """í™œì„± ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒˆ ì„¸ì…˜ ìƒì„±"""
        # í™œì„± ì„¸ì…˜ í™•ì¸
        active_session = ChatSession.objects.filter(
            user=user,
            is_active=True
        ).first()
        
        if active_session:
            # ë§ˆì§€ë§‰ í™œë™ì´ 1ì‹œê°„ ì´ìƒ ì§€ë‚¬ìœ¼ë©´ ìƒˆ ì„¸ì…˜ ì‹œì‘
            last_message = active_session.messages.order_by('-created_at').first()
            if last_message and (timezone.now() - last_message.created_at).seconds > 3600:
                active_session.end_session()
                active_session = None
        
        if not active_session:
            # ìƒˆ ì„¸ì…˜ ìƒì„±
            active_session = ChatSession.objects.create(user=user)
            logger.debug(f"ğŸ“ ìƒˆ ì„¸ì…˜ ìƒì„±: {active_session.id}")
        
        return active_session
    
    def _get_user_context(self, user) -> Dict:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘"""
        user_context = {'username': user.username}
        
        if hasattr(user, 'profile'):
            profile = user.profile
            
            # BMI ê³„ì‚°
            bmi = None
            if profile.height and profile.weight:
                height_m = profile.height / 100
                bmi = round(profile.weight / (height_m ** 2), 1)
            
            user_context.update({
                'age': profile.age,
                'height': profile.height,
                'weight': profile.weight,
                'bmi': bmi,
                'gender': profile.get_gender_display(),
                'exercise_experience': profile.get_exercise_experience_display(),
                'diseases': profile.diseases or [],
                'allergies': profile.allergies or [],
                'preferred_exercises': profile.preferred_exercises or [],
                'preferred_foods': profile.preferred_foods or [],
                'disliked_exercises': profile.disliked_exercises or [],
                'disliked_foods': profile.disliked_foods or []
            })
        
        return user_context
    
    def _create_system_prompt(self, user, user_context: Dict) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = "ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ í—¬ìŠ¤ì¼€ì–´ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
        prompt += "ì‚¬ìš©ìì˜ ê±´ê°• ì •ë³´ì™€ ì„ í˜¸ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ë§ì¶¤í˜• ìš´ë™ê³¼ ì‹ë‹¨ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n\n"
        
        prompt += f"""
ì‚¬ìš©ì ì •ë³´:
- ì´ë¦„: {user_context.get('username', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- ë‚˜ì´: {user_context.get('age', 'ì•Œ ìˆ˜ ì—†ìŒ')}ì„¸
- ì„±ë³„: {user_context.get('gender', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- í‚¤: {user_context.get('height', 'ì•Œ ìˆ˜ ì—†ìŒ')}cm
- ì²´ì¤‘: {user_context.get('weight', 'ì•Œ ìˆ˜ ì—†ìŒ')}kg
- BMI: {user_context.get('bmi', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- ìš´ë™ ê²½ë ¥: {user_context.get('exercise_experience', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- ì§ˆë³‘: {', '.join(user_context.get('diseases', [])) or 'ì—†ìŒ'}
- ì•Œë ˆë¥´ê¸°: {', '.join(user_context.get('allergies', [])) or 'ì—†ìŒ'}

ë‹µë³€ ì‹œ ì‚¬ìš©ìì˜ ê±´ê°• ìƒíƒœ, ì„ í˜¸ë„, ì œí•œì‚¬í•­ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì„¸ìš”.
"""
        
        return prompt
    
    def _extract_preferences_from_text(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ ì„ í˜¸ë„ ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)"""
        preferences = {
            'liked_exercises': [],
            'disliked_exercises': [],
            'liked_foods': [],
            'disliked_foods': [],
            'other_preferences': {}
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œë§Œ ìˆ˜í–‰
        text_lower = text.lower()
        
        # ë§¤ìš´ ìŒì‹ í‚¤ì›Œë“œ ê²€ìƒ‰
        if any(word in text_lower for word in ['ë§¤ìš´', 'ë§¤ì›Œ', 'ë§µê²Œ', 'ë§µë‹¤']):
            if any(word in text_lower for word in ['ì‹«ì–´', 'ì‹«ë‹¤', 'ëª» ë¨¹', 'ì•ˆ ë¨¹']):
                preferences['other_preferences']['spicy_preference'] = 'dislike'
            elif any(word in text_lower for word in ['ì¢‹ì•„', 'ì¢‹ë‹¤', 'ì˜ ë¨¹']):
                preferences['other_preferences']['spicy_preference'] = 'like'
        
        return preferences
    
    def _update_user_preferences(self, user, preferences: Dict):
        """ì‚¬ìš©ì í”„ë¡œí•„ì— ì„ í˜¸ë„ ì—…ë°ì´íŠ¸"""
        try:
            profile = user.profile
            
            # ë§¤ìš´ ìŒì‹ ì„ í˜¸ë„ ì²˜ë¦¬
            other_prefs = preferences.get('other_preferences', {})
            if other_prefs.get('spicy_preference') == 'dislike':
                disliked = profile.disliked_foods or []
                if 'ë§¤ìš´ ìŒì‹' not in disliked:
                    disliked.append('ë§¤ìš´ ìŒì‹')
                    profile.disliked_foods = disliked
                    profile.save()
                    
                    # ìºì‹œ ë¬´íš¨í™”
                    cache.delete(f"user_context:{user.id}")
                    
        except Exception as e:
            logger.error(f"ì„ í˜¸ë„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    def _generate_daily_recommendations(self, user):
        """ì¼ì¼ ì¶”ì²œ ìƒì„± (ê°„ë‹¨í•œ ì²´í¬ë§Œ)"""
        today = timezone.now().date()
        
        # ì˜¤ëŠ˜ì˜ ì¶”ì²œì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        existing = DailyRecommendation.objects.filter(
            user=user,
            date=today
        ).exists()
        
        if not existing:
            # ì‹¤ì œ ìƒì„±ì€ ë³„ë„ íƒœìŠ¤í¬ë¡œ ì²˜ë¦¬
            logger.info(f"ì¼ì¼ ì¶”ì²œ ìƒì„± í•„ìš”: {user.username}")
    
    def get_conversation_history(self, user, limit: int = 50) -> List[Dict]:
        """ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°"""
        # ìºì‹œ í™•ì¸
        cache_key = f"chat_history:{user.id}:{limit}"
        cached_history = cache.get(cache_key)
        if cached_history:
            return cached_history
        
        # ìµœê·¼ ì„¸ì…˜ë“¤ì˜ ë©”ì‹œì§€
        recent_sessions = ChatSession.objects.filter(
            user=user
        ).order_by('-started_at')[:self.max_recent_sessions]
        
        messages = ChatMessage.objects.filter(
            session__in=recent_sessions
        ).order_by('-created_at')[:limit]
        
        history = []
        for msg in reversed(messages):
            history.append({
                'id': msg.id,
                'session_id': msg.session_id,
                'sender': msg.sender,
                'message': msg.message,
                'timestamp': msg.created_at.isoformat(),
                'context': msg.context
            })
        
        # ìºì‹œì— ì €ì¥
        cache.set(cache_key, history, 60)  # 1ë¶„ ìºì‹œ
        return history
    
    def clear_user_cache(self, user_id: int):
        """ì‚¬ìš©ì ìºì‹œ ì‚­ì œ"""
        # ëª¨ë“  ê´€ë ¨ ìºì‹œ ì‚­ì œ
        cache_keys = [
            f"user_context:{user_id}",
            f"system_prompt:{user_id}:*",
            f"chat_history:{user_id}:*"
        ]
        
        for key_pattern in cache_keys:
            if '*' in key_pattern:
                # íŒ¨í„´ ë§¤ì¹­ì€ Redis ë“± ê³ ê¸‰ ìºì‹œ ë°±ì—”ë“œì—ì„œë§Œ ì§€ì›
                pass
            else:
                cache.delete(key_pattern)
        
        # í˜„ì¬ í™œì„± ì„¸ì…˜ ì¢…ë£Œ
        ChatSession.objects.filter(
            user_id=user_id,
            is_active=True
        ).update(is_active=False, ended_at=timezone.now())


# ì „ì—­ ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤
chatbot_instance = None

def get_chatbot() -> OptimizedHealthChatbot:
    """ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global chatbot_instance
    if not chatbot_instance:
        chatbot_instance = OptimizedHealthChatbot()
    return chatbot_instance
